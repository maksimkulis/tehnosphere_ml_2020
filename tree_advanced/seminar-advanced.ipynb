{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Быстро строим деревья"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Деревья глубины 1 обычно называют решающими пнями. \n",
    "Как Вы думаете, какая сложность построения решающего пня?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Представим, что мы решаем задачу регрессии, считаем для одного сплита. \n",
    "\n",
    "$$Q = F(R_m) - \\frac{N_l}{N_m} F(R_l) - \\frac{N_r}{N_m} F(R_r) $$\n",
    "\n",
    "$$F(R) = \\frac{1}{N} \\sum_{i=1}^{N}(mean(y) - y_i) ^ 2 $$\n",
    "\n",
    "$$Q = F(R_m) - \\frac{1}{N_m} [ \\sum_{i \\in R_l}(mean(y_l) - y_i) ^ 2  +  \\sum_{i \\in R_r}(mean(y_r) - y_i) ^ 2 ]  $$\n",
    "\n",
    "$F(R_m) и N_m$ от сплита не зависит, можно отбросить. Осталось научиться быстро считать такие выражения:\n",
    "$\\sum_{i \\in R_l}(mean(y_l) - y_i) ^ 2$ для всех порогов. \n",
    "\n",
    "Если делать в лоб, то получится $O(||R||^2)$, нам не нравится, очень долго. Каждый раз пересчитывать довольно глупо, потому что мы точно знаем, какой именно объект при изменении сплита перешел из левой части в правую!\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Воспользуемся формулой для дисперсии:\n",
    "$$D(R) = mean(y ^ 2) -  mean(y) ^ 2 =   \\frac{1}{N} \\sum_{i \\in R} y_i^2 -  \\frac{1}{N ^ 2} (\\sum_{i \\in R} y_i) ^2$$\n",
    "\n",
    "Но у нас не дисперсия, а дисперсия без деления на число объектов, то есть:\n",
    "$$\\sum_{i \\in R_l}(mean(y_l) - y_i) ^ 2 =   \\sum_{i \\in R_k} y_i^2 -  \\frac{1}{N_l} (\\sum_{i \\in R_l} y_i) ^2 $$\n",
    "Аналогично для правого сплита. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вот мы и получили более простой алгоритм подсчета сплита:\n",
    "\n",
    "1) Отсортировали фичу и таргет по фиче\n",
    "\n",
    "2) Сначала считаем, что порог это минимальное значение, то есть левый кусок пустой, правый все значения. Храним для каждой из частей\n",
    "а) Сумму\n",
    "б) Сумму квадратов\n",
    "в) Число объектов\n",
    "\n",
    "3) Взяли следующее значение в отсортированном списке, это значение ушло от правого куска в левое. Обновили а) б) в) в обоих кусках\n",
    "\n",
    "4) Посчитали  для каждого куска б) - а) ** 2 / в), сложили для обоих кусков. Если эта сумма маеньше лучшего значения, то это лучший сплит из текущих\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Реализуйте алгоритм, сравните качество со sklearn.\n",
    "\n",
    "Если получилось одинаково, Вы молодец!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_threshold(feature, y, train_mode=\"kek\"):\n",
    "    best_thr = None\n",
    "    if len(y) == 0:\n",
    "        return best_thr\n",
    "    \n",
    "    sorted_indexes = np.argsort(feature)\n",
    "    \n",
    "    right_sq_sum = np.sum(y ** 2)\n",
    "    right_lin_sum = np.sum(y)\n",
    "    \n",
    "    left_sq_sum = left_lin_sum = 0\n",
    "    \n",
    "    N = len(y)\n",
    "    F_R = (right_sq_sum - right_lin_sum ** 2 / N) / N \n",
    "    \n",
    "    F = np.inf\n",
    "    l_mean = r_mean = None\n",
    "    for it, ind in enumerate(sorted_indexes[:-1], 1):\n",
    "        right_sq_sum -= y[ind] ** 2\n",
    "        right_lin_sum -= y[ind]\n",
    "        left_sq_sum += y[ind] ** 2\n",
    "        left_lin_sum += y[ind]\n",
    "        \n",
    "        F_tmp = ((left_sq_sum - left_lin_sum ** 2 / it) + \\\n",
    "                 (right_sq_sum - right_lin_sum ** 2 / (N - it))) / N\n",
    "        if F_tmp < F:\n",
    "            F = F_tmp\n",
    "            best_thr = feature[ind]\n",
    "            l_mean = left_lin_sum / it\n",
    "            r_mean = right_lin_sum / (N - it)\n",
    "        \n",
    "    # YOUR CODE HEREa\n",
    "    return F, best_thr, l_mean, r_mean\n",
    "\n",
    "\n",
    "def train_stump(X, y):\n",
    "    best_f = None\n",
    "    best_thr = None\n",
    "    best_error = float('inf')\n",
    "    left_mean, right_mean = None, None\n",
    "    for j in range(X.shape[1]):\n",
    "        f_score, f_thr, l_mean, r_mean = get_threshold(X[:, j], y)\n",
    "        if f_score < best_error:\n",
    "            best_error = f_score\n",
    "            best_f = j\n",
    "            best_thr = f_thr\n",
    "            left_mean = l_mean\n",
    "            right_mean = r_mean\n",
    "    return best_f, best_thr, left_mean, right_mean\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_predict(X, best_f, best_thr, left_mean, right_mean):\n",
    "#     best_f, best_thr, left_mean, right_mean = train_stump(X, y)\n",
    "    left_mask = X[:, best_f] < best_thr\n",
    "    res = np.zeros(shape=X.shape[0])\n",
    "    res[left_mask] = left_mean\n",
    "    res[~left_mask] = right_mean\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "X, y = load_boston(return_X_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "46.19909167710848\n",
      "46.33492394342731\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(5, 6.939, 19.933720930232564, 37.23815789473695)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "regressor = DecisionTreeRegressor(random_state=0).fit(X, y)\n",
    "print(mean_squared_error(y, regressor.predict(X)))\n",
    "regressor_stump = DecisionTreeRegressor(random_state=0, max_depth=1).fit(X, y)\n",
    "print(mean_squared_error(y, regressor_stump.predict(X)))\n",
    "\n",
    "# My model\n",
    "print(mean_squared_error(y, my_predict(X, *train_stump(X, y))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%time\n",
    "a = "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
